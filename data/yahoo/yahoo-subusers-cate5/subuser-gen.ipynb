{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3f0e671",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:20:05.688816Z",
     "start_time": "2023-04-23T09:20:05.056774Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyper-parameters\n",
    "user_clip_num = 2\n",
    "user_pos_num_clip = 2 # only split users with training positive interactions >= user_clip_num * user_pos_num_clip\n",
    "max_interact_num = 10\n",
    "like_threshold = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce855e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:20:10.329162Z",
     "start_time": "2023-04-23T09:20:05.690819Z"
    }
   },
   "outputs": [],
   "source": [
    "data_string = open('../yahoo-origin/user.txt', 'r', encoding = \"ISO-8859-1\").read().strip().split('\\n')\n",
    "data_dict = {\"user_id\":[],\"item_id\":[],\"score\":[]}\n",
    "for da in data_string:\n",
    "    l_string = da.split(',')\n",
    "    data_dict[\"user_id\"].append(eval(l_string[0]))\n",
    "    data_dict[\"item_id\"].append(eval(l_string[1]))\n",
    "    data_dict[\"score\"].append(eval(l_string[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5adb03e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:20:10.345166Z",
     "start_time": "2023-04-23T09:20:10.333163Z"
    }
   },
   "outputs": [],
   "source": [
    "path='./features'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "path='./sets'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e74cd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:20:10.583187Z",
     "start_time": "2023-04-23T09:20:10.347167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311704, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_raw = pd.DataFrame(data_dict)\n",
    "train_data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ddc0564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:20:10.615190Z",
     "start_time": "2023-04-23T09:20:10.585188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125077, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pos = train_data_raw[train_data_raw.score>3]\n",
    "train_data_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "729fd790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:20:10.647192Z",
     "start_time": "2023-04-23T09:20:10.617192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    14382\n",
       "item_id     1000\n",
       "score          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pos.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4cc0c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:20:11.445253Z",
     "start_time": "2023-04-23T09:20:10.650196Z"
    }
   },
   "outputs": [],
   "source": [
    "data_string2 = open('../yahoo-origin/random.txt', 'r', encoding = \"ISO-8859-1\").read().strip().split('\\n')\n",
    "data_dict2 = {\"user_id\":[],\"item_id\":[],\"score\":[]}\n",
    "for da in data_string2:\n",
    "    l_string = da.split(',')\n",
    "    data_dict2[\"user_id\"].append(eval(l_string[0]))\n",
    "    data_dict2[\"item_id\"].append(eval(l_string[1]))\n",
    "    data_dict2[\"score\"].append(eval(l_string[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb24e94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:20:11.509258Z",
     "start_time": "2023-04-23T09:20:11.447255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_raw = pd.DataFrame(data_dict2)\n",
    "test_data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ddce89a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:20:25.384289Z",
     "start_time": "2023-04-23T09:20:11.514258Z"
    }
   },
   "outputs": [],
   "source": [
    "for id in test_data_raw.user_id.unique():\n",
    "    if id not in train_data_pos.user_id.unique():\n",
    "        test_data_raw = test_data_raw[test_data_raw.user_id!=id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb9013a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:20:25.400292Z",
     "start_time": "2023-04-23T09:20:25.386293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50590, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c5383c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T09:20:25.415291Z",
     "start_time": "2023-04-23T09:20:25.402296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4671, 3)\n",
      "2383\n"
     ]
    }
   ],
   "source": [
    "test_data_pos = test_data_raw[test_data_raw.score>3]\n",
    "print(test_data_pos.shape)\n",
    "print(test_data_pos.user_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504344ed",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.036Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████▌| 124424/125077 [00:27<00:00, 4515.89it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "item_id_map = {}\n",
    "user_id_map = {}\n",
    "userID = 0\n",
    "itemID = 0\n",
    "big_pos_list = []\n",
    "train_data = train_data_pos.copy(deep=True)\n",
    "for i in tqdm(range(train_data.shape[0])):\n",
    "    if train_data.iloc[i,0] in user_id_map:\n",
    "        train_data.iloc[i,0] = user_id_map[train_data.iloc[i,0]]\n",
    "    else:\n",
    "        uID = userID\n",
    "        user_id_map[train_data.iloc[i,0]]=uID\n",
    "        train_data.iloc[i,0] = uID\n",
    "        userID += 1\n",
    "    #print(train_data.iloc[i,1])\n",
    "    if train_data.iloc[i,1] in item_id_map:\n",
    "        # print(\"train_data.iloc[i,1]\",train_data.iloc[i,1])\n",
    "        # print(\"item_id_map:\",item_id_map)\n",
    "        train_data.iloc[i,1] = item_id_map[train_data.iloc[i,1]]\n",
    "    else:\n",
    "        iID = itemID\n",
    "        item_id_map[train_data.iloc[i,1]]=iID\n",
    "        train_data.iloc[i,1] = iID\n",
    "        itemID += 1  \n",
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6524bd5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.038Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76057c6e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.040Z"
    }
   },
   "outputs": [],
   "source": [
    "# added for splitting users: only split training data, keep testing data untouched.\n",
    "big_matrix = train_data_raw\n",
    "user_all_dict = {} # to record every exposure interaction with time and watch_ratio(here only with score)\n",
    "for i in tqdm(range(big_matrix.shape[0])):\n",
    "    if big_matrix.iloc[i,0] in user_id_map:\n",
    "        uID = user_id_map[big_matrix.iloc[i,0]]\n",
    "        \n",
    "        # this is a recorded positive interaction\n",
    "        if big_matrix.iloc[i,2]>=4: \n",
    "            iID = item_id_map[big_matrix.iloc[i,1]]\n",
    "#             assert [uID, iID] in big_pos_list # double check this is recorded\n",
    "            \n",
    "            if uID not in user_all_dict:\n",
    "                user_all_dict[uID] = {'exposure':[], 'like':[]}\n",
    "            user_all_dict[uID]['exposure'].append([iID, big_matrix.iloc[i,2]])\n",
    "            user_all_dict[uID]['like'].append([iID, big_matrix.iloc[i,2]])\n",
    "            \n",
    "        # this is a negative interaction\n",
    "        else:\n",
    "            if big_matrix.iloc[i,1] in item_id_map: \n",
    "                iID = item_id_map[big_matrix.iloc[i,1]]\n",
    "            # this is a new item unmapped\n",
    "            else: \n",
    "                iID = len(item_id_map)\n",
    "                item_id_map[big_matrix.iloc[i,1]] = iID\n",
    "                \n",
    "            if uID not in user_all_dict:\n",
    "                user_all_dict[uID] = {'exposure':[], 'like':[]}\n",
    "            user_all_dict[uID]['exposure'].append([iID, big_matrix.iloc[i,2]])\n",
    "    else:\n",
    "        continue # this user is deleted in previous MF data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a841954",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.041Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_item = np.load(\"./embed_item_MF_yahoo_512factor_num_0.0001lr_256bs_0.0dropout.npy\")\n",
    "\n",
    "import pandas as pd  \n",
    "from sklearn.cluster import KMeans  \n",
    "import matplotlib.pyplot as plt  \n",
    "from tqdm import tqdm\n",
    "category_num_new = 5\n",
    "kmeans_model = KMeans(category_num_new, random_state=1)\n",
    "kmeans_model.fit(embed_item)\n",
    "labels = kmeans_model.labels_\n",
    "\n",
    "# create item_feature_dict file CHANGED!!!\n",
    "item_feature_dict = {}\n",
    "for item in range(embed_item.shape[0]):\n",
    "    item_feature_dict[item] = [labels[item]]\n",
    "\n",
    "np.save('./features/item_feature_dict.npy', np.array(item_feature_dict))\n",
    "\n",
    "# create category_list file\n",
    "category_list = list(range(category_num_new))\n",
    "np.save('./features/category_list.npy', np.array(category_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e75f3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.042Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data0 = test_data_pos.copy(deep=True)\n",
    "for i in tqdm(range(test_data0.shape[0])):\n",
    "    if test_data0.iloc[i,0] in user_id_map:\n",
    "        test_data0.iloc[i,0] = user_id_map[test_data0.iloc[i,0]]\n",
    "    else:\n",
    "        print('u',uID)\n",
    "    if test_data0.iloc[i,1] in item_id_map:\n",
    "        test_data0.iloc[i,1] = item_id_map[test_data0.iloc[i,1]]\n",
    "    else:\n",
    "        print('i',iID)\n",
    "# test_data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28fd1f5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.044Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dict=train_data.sort_values('user_id').groupby('user_id')\n",
    "train_user_id=train_data.user_id.unique()\n",
    "training_dict=dict()\n",
    "for i in train_user_id:\n",
    "    training_dict[i]=train_dict.get_group(i).item_id.values.tolist()\n",
    "training_list = []\n",
    "for u in training_dict:\n",
    "    for i in training_dict[u]:\n",
    "        training_list.append([u,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3331c4f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.045Z"
    }
   },
   "outputs": [],
   "source": [
    "# split users and generate new big_pos_dict and big_pos_list.\n",
    "big_pos_dict = dict(training_dict)\n",
    "big_pos_list = list(training_list)\n",
    "# a function to calc T given exposure items and item_category_dict&category_list\n",
    "def calc_T(t_seq, item_category, category_list):\n",
    "    cate_dis = [0] * (max(category_list)+1)\n",
    "    for item in t_seq:\n",
    "        for c in item_category[item]:\n",
    "            cate_dis[c] += 1/len(item_category[item])\n",
    "    cate_dis = [c/len(t_seq) for c in cate_dis]\n",
    "    return cate_dis\n",
    "\n",
    "# a function to calc Y given exposure items, liked items, and item_category_dict&category_list\n",
    "def calc_Y(t_seq, next_d, item_category, category_list):\n",
    "    exposure_dis = [0]* (max(category_list)+1)\n",
    "    like_dis = [0]* (max(category_list)+1)\n",
    "    for item in t_seq:\n",
    "        for c in item_category[item]:\n",
    "            exposure_dis[c] += 1/len(item_category[item])\n",
    "    for item in next_d:\n",
    "        for c in item_category[item]:\n",
    "            like_dis[c] += 1/len(item_category[item])\n",
    "    ctr_dis = [like_dis[c]/exposure_dis[c] if exposure_dis[c] > 0 else 0 for c in range(len(exposure_dis))]\n",
    "    return ctr_dis\n",
    "    \n",
    "subuser_all_dict = {} # subuserID\n",
    "user_subuser_map = {}\n",
    "user_subuser_exp_dict = {} # save exposure data of users and subusers\n",
    "user_num = len(user_id_map)\n",
    "assert user_num not in big_pos_dict\n",
    "\n",
    "for uID in tqdm(user_all_dict):\n",
    "    pos_num = len(user_all_dict[uID]['like'])\n",
    "    \n",
    "    # save exposure data of uID\n",
    "    user_subuser_exp_dict[uID] = [entry[0] for entry in user_all_dict[uID]['exposure']]\n",
    "    \n",
    "    # only split users with postive len > user_clip_num * user_pos_num_clip\n",
    "    if pos_num < user_clip_num * user_pos_num_clip:\n",
    "        continue\n",
    "    pos_num_clip = pos_num//user_clip_num\n",
    "    for i in range(user_clip_num-1):\n",
    "        \n",
    "        subuser_id = user_num\n",
    "        user_num += 1\n",
    "        user_subuser_map[subuser_id] = uID\n",
    "        subuser_all_dict[subuser_id] = {}\n",
    "        \n",
    "        # find like history in current clip\n",
    "        d = user_all_dict[uID]['like'][:(i+1)*pos_num_clip]\n",
    "        \n",
    "        # find treatment in next clip\n",
    "        st = user_all_dict[uID]['exposure'].index(user_all_dict[uID]['like'][(i+1)*pos_num_clip])\n",
    "        if i != user_clip_num-2: # not last clip\n",
    "            ed = user_all_dict[uID]['exposure'].index(user_all_dict[uID]['like'][(i+2)*pos_num_clip])\n",
    "            t_seq = user_all_dict[uID]['exposure'][st:ed]\n",
    "        else:\n",
    "            t_seq = user_all_dict[uID]['exposure'][st:]\n",
    "            \n",
    "        # find like history in next clip\n",
    "        if i != user_clip_num-2: # not last clip\n",
    "            next_d = user_all_dict[uID]['like'][(i+1)*pos_num_clip:(i+2)*pos_num_clip]\n",
    "        else:\n",
    "            next_d = user_all_dict[uID]['like'][(i+1)*pos_num_clip:]\n",
    "        \n",
    "        # save exposure data of subuser_id: find the last liked item and save its exposure.\n",
    "        exposure_index = user_all_dict[uID]['exposure'].index(d[-1])\n",
    "        user_subuser_exp_dict[subuser_id] = user_all_dict[uID]['exposure'][:exposure_index+1]\n",
    "        \n",
    "        d = [entry[0] for entry in d]\n",
    "        next_d = [entry[0] for entry in next_d]\n",
    "        t_seq = [entry[0] for entry in t_seq]\n",
    "        \n",
    "        T = calc_T(t_seq, item_feature_dict, category_list)\n",
    "        Y = calc_Y(t_seq, next_d, item_feature_dict, category_list)\n",
    "\n",
    "        subuser_all_dict[subuser_id]['D'] = d\n",
    "        subuser_all_dict[subuser_id]['T'] = T\n",
    "        subuser_all_dict[subuser_id]['Y'] = Y\n",
    "                \n",
    "        # update big_pos_dict and big_pos_list\n",
    "        for item in d:\n",
    "            if subuser_id not in big_pos_dict:\n",
    "                big_pos_dict[subuser_id] = []\n",
    "            big_pos_dict[subuser_id].append(item)\n",
    "            big_pos_list.append([subuser_id, item])\n",
    "\n",
    "        if uID == 0:\n",
    "            print(subuser_all_dict[subuser_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ba049",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.046Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('./sets/training_dict.npy',np.array(big_pos_dict)) # 保存为.npy格式\n",
    "np.save('./sets/training_list.npy',np.array(big_pos_list)) # 保存为.npy格式\n",
    "np.save('./features/user_subuser_exp_dict.npy', np.array(user_subuser_exp_dict))\n",
    "np.save('./features/user_subuser_map.npy', np.array(user_subuser_map))\n",
    "np.save('./features/subuser_info.npy', np.array(subuser_all_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1404ad",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.048Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def split_pandas_data_with_ratios(data, ratios, shuffle=False):\n",
    "    \"\"\"\n",
    "    按输入的比例列表对数据进行切分\n",
    "    Args:\n",
    "        data (pd.DataFrame): Pandas DataFrame 格式的数据.\n",
    "        ratios (list of floats): 切分比例的列表，和需要是 1.\n",
    "        shuffle (bool): 是否需要洗牌.\n",
    "\n",
    "    Returns:\n",
    "        list: 切分后的数据列表，列表中的元素类型为 pd.DataFrame .\n",
    "    \"\"\"\n",
    "    # 检查 切分比例的列表是否和为 1\n",
    "    if math.fsum(ratios) != 1.0:\n",
    "        raise ValueError(\"切分比例需要其和为1\")\n",
    "        \n",
    "    # 累加求和，例如 [0.7,0.15,0.15] 累计求和为 [0.7, 0.85, 1]\n",
    "    # 然后剔除最后一个值，即结果为 [0.7, 0.85]\n",
    "    split_index = np.cumsum(ratios).tolist()[:-1]\n",
    "    \n",
    "    # 是否洗牌\n",
    "    if shuffle:\n",
    "        # 不放回的从原始数据中随机取数据，直到到达frac设置的比例\n",
    "        data = data.sample(frac=1)\n",
    "    # 切分\n",
    "    #print(\"data_size:\",len(data))\n",
    "\n",
    "    splits = np.split(data, [round(x * len(data)) for x in split_index])\n",
    "\n",
    "    #对于valid为0的处理（只能处理训练集和验证集\n",
    "    # if(len(splits[0])==1):\n",
    "    #     splits[1]=splits[0].copy()\n",
    "\n",
    "    split_index_small=[ 0.5, 1 ]\n",
    "    if(len(splits[1])==0):\n",
    "        splits = np.split(data, [round(x * len(data)) for x in split_index_small])\n",
    "\n",
    "    for i in range(len(ratios)):\n",
    "        splits[i][\"split_index\"] = i\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24c9d5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.049Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped = test_data0.groupby('user_id')\n",
    "splits = []\n",
    "ratio=[0.5,0.5]\n",
    "\n",
    "# 对于每一名用户\n",
    "for name, group in df_grouped:\n",
    "    if(df_grouped.get_group(name).shape[0]<2):\n",
    "        continue\n",
    "    group_splits = split_pandas_data_with_ratios(df_grouped.get_group(name), ratio)\n",
    "    # 把切分好的数据再合并，数据值只多了 split_index 这一列\n",
    "    concat_group_splits = pd.concat(group_splits)\n",
    "    splits.append(concat_group_splits)\n",
    "\n",
    "# 把所有用户的数据合并\n",
    "splits_all = pd.concat(splits)\n",
    "\n",
    "# 按照 split_index 标记把数据切分出来\n",
    "splits_list = [\n",
    "    splits_all[splits_all[\"split_index\"] == x].drop(\"split_index\", axis=1)\n",
    "    for x in range(len(ratio))\n",
    "]\n",
    "valid_data=splits_list[0]\n",
    "test_data=splits_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821243d5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.051Z"
    }
   },
   "outputs": [],
   "source": [
    "train_user_id=train_data.user_id.unique()\n",
    "validation_id=valid_data.user_id.unique()\n",
    "test_id=test_data.user_id.unique()\n",
    "print(list(validation_id)==list(test_id))\n",
    "for i in validation_id:\n",
    "    if i not in train_user_id:\n",
    "        print(i,\" not in training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c8f145",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.053Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_dict=valid_data.groupby('user_id')\n",
    "valid_user_id=valid_data.sort_values('user_id').user_id.unique()\n",
    "validation_dict=dict()\n",
    "for i in valid_user_id:\n",
    "    validation_dict[i]=valid_dict.get_group(i).item_id.values.tolist()\n",
    "np.save('./sets/validation_dict.npy',np.array(validation_dict)) # 保存为.npy格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d89d3e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.054Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dict=test_data.groupby('user_id')\n",
    "test_user_id=test_data.sort_values('user_id').user_id.unique()\n",
    "testing_dict=dict()\n",
    "for i in test_user_id:\n",
    "    testing_dict[i]=test_dict.get_group(i).item_id.values.tolist()\n",
    "np.save('./sets/testing_dict.npy',np.array(testing_dict)) # 保存为.npy格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef6218",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.056Z"
    }
   },
   "outputs": [],
   "source": [
    "pop_rank = dict(pd.DataFrame(training_list)[1].value_counts())\n",
    "print(len(pop_rank))\n",
    "for item in item_id_map:\n",
    "    i = item_id_map[item]\n",
    "    if i not in pop_rank:\n",
    "        pop_rank[i] = 0\n",
    "print(len(pop_rank))\n",
    "\n",
    "item_rank_dict = {} #id:rank\n",
    "rank = 0\n",
    "for element in pop_rank:\n",
    "    item_rank_dict[element] = rank\n",
    "    rank += 1\n",
    "np.save('./features/item_rank_dict.npy', np.array(item_rank_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c395062",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.057Z"
    }
   },
   "outputs": [],
   "source": [
    "category_num = len(category_list)\n",
    "topk_category = 3\n",
    "user_fml_cat_big = {}\n",
    "for user in training_dict:\n",
    "    category_cnt = [0] * category_num\n",
    "    for item in training_dict[user]:\n",
    "        for cat in item_feature_dict[item]:\n",
    "            category_cnt[cat] += 1\n",
    "    sorted_list = list(np.argsort(category_cnt))\n",
    "    fml_cat = sorted_list[-topk_category:]\n",
    "    user_fml_cat_big[user] = fml_cat\n",
    "np.save('./features/user_fml_cat.npy', np.array(user_fml_cat_big))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be07415",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.059Z"
    }
   },
   "outputs": [],
   "source": [
    "user_feature_file = {}\n",
    "for userID in big_pos_dict:\n",
    "    user_feature_file[userID] = [['U'+str(userID)]]\n",
    "    user_feature_file[userID].append([str(1)]*len(user_feature_file[userID][0]))\n",
    "\n",
    "item_feature_file = {}\n",
    "for itemID in item_feature_dict:\n",
    "    item_feature_file[itemID] = [['I'+str(itemID)]]\n",
    "    item_feature_file[itemID].append(['1'])\n",
    "    for cate in range(0, len(category_list)):\n",
    "        if cate in item_feature_dict[itemID]:\n",
    "            item_feature_file[itemID][0].append('IC'+str(cate))\n",
    "            item_feature_file[itemID][1].append(str(round(1.0/len(item_feature_dict[itemID]), 2)))\n",
    "        else:\n",
    "            item_feature_file[itemID][0].append('IC'+str(cate))\n",
    "            item_feature_file[itemID][1].append(str(0))\n",
    "np.save('./features/user_feature_file.npy', np.array(user_feature_file))\n",
    "np.save('./features/item_feature_file.npy', np.array(item_feature_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b6e91",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:20:05.061Z"
    }
   },
   "outputs": [],
   "source": [
    "item_cat_vec = {}\n",
    "for itemID in item_feature_dict: \n",
    "    item_cat_vec[itemID] = [0] * category_num\n",
    "    cat_num = len(item_feature_dict[itemID])\n",
    "    for cat in item_feature_dict[itemID]:\n",
    "        item_cat_vec[itemID][cat] = 1 / np.sqrt(cat_num)\n",
    "np.save('./features/item_cat_vec.npy', np.array(item_cat_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83398b30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
